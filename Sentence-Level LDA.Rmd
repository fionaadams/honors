---
title: "Sentence-Level LDA"
author: "Fiona Adams"
date: "1/10/2020"
output: html_document
---

Goal for this document: 
-take clean dataset
-perform LDA to get clusters of words that go together
-get the words from each cluster

```{r}
new <- read.csv("sentence_level_clean.csv", header = TRUE)

new <- new %>%
    mutate(
        X = NULL,
        ID = as.character(ID),
        sentences = as.character(sentences)
    )
```

```{r echo=FALSE, warning=FALSE, results="hide", message=FALSE}
require(text2vec)

set.seed(397)

tokenlen = (length(new$sentences)/3) * 2

tokens = new$sentences[1:tokenlen] %>% 
  tolower %>%
  word_tokenizer

it = itoken(tokens, ids = new$ID[1:tokenlen], progressbar = FALSE)
v = create_vocabulary(it) %>% 
  prune_vocabulary(term_count_min = 10, doc_proportion_max = 0.2)
vectorizer = vocab_vectorizer(v)
dtm = create_dtm(it, vectorizer, type = "dgTMatrix")

lda_model = LDA$new(n_topics = 20, doc_topic_prior = 0.1, topic_word_prior = 0.01)
doc_topic_distr = 
  lda_model$fit_transform(x = dtm, n_iter = tokenlen, 
                          convergence_tol = 0.001, n_check_convergence = 25, 
                          progressbar = FALSE)
```

```{r echo=FALSE, fig.align="center"}
barplot(doc_topic_distr[1, ], xlab = "topic", 
        ylab = "proportion", main="Proportion of Documents (Sentences) in each Topic", ylim = c(0, 1), 
        names.arg = 1:ncol(doc_topic_distr))
```

```{r echo=FALSE, results="hide", message=FALSE}
new_dtm = itoken(new$sentences[tokenlen:length(new$sentences)], tolower, word_tokenizer, ids = new$ID[tokenlen:length(new$sentences)]) %>% 
  create_dtm(vectorizer, type = "dgTMatrix")
new_doc_topic_distr = lda_model$transform(new_dtm)
```

Info on sharing this visualization: https://github.com/cpsievert/LDAvis
```{r message=FALSE}
library(LDAvis)
lda_model$plot()
```

Get words from first cluster
```{r}
top_words <- lda_model$get_top_words(n = 30, lambda = 0.3)
top_words[,1]
```



