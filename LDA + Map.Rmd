---
title: "LDA + Map"
author: "Fiona Adams"
date: "2/9/2020"
output: html_document
---
```{r}
library(stringr)
```

```{r}
new <- read.csv("udpipe_clean_sentences.csv")
```

#Perform LDA
```{r echo=FALSE, warning=FALSE, results="hide", message=FALSE}
require(text2vec)

set.seed(397)

tokenlen = (length(new$sentence)/3) * 2

tokens = new$sentence[1:tokenlen] %>% 
  tolower %>%
  word_tokenizer

it = itoken(tokens, ids = new$id[1:tokenlen], progressbar = FALSE)
v = create_vocabulary(it) %>% 
  prune_vocabulary(term_count_min = 10, doc_proportion_max = 0.2)
vectorizer = vocab_vectorizer(v)
dtm = create_dtm(it, vectorizer, type = "dgTMatrix")

lda_model = LDA$new(n_topics = 20, doc_topic_prior = 0.1, topic_word_prior = 0.01)
doc_topic_distr = 
  lda_model$fit_transform(x = dtm, n_iter = tokenlen, 
                          convergence_tol = 0.001, n_check_convergence = 25, 
                          progressbar = FALSE)
```

Info on sharing this visualization: https://github.com/cpsievert/LDAvis
```{r message=FALSE}
library(LDAvis)
lda_model$plot()
```

#Extract cluster words, make only unique words
```{r}
words_in_clusters <- lda_model$get_top_words(n = 30, lambda = 0.3)
words_in_clusters <- as.data.frame(words_in_clusters) %>% 
  mutate_all(as.character)
```

#Map the clusters
```{r}
check.cluster.i <- function(df, i){
  listofwords <- words_in_clusters[,i]
  pattern <- paste(listofwords, collapse = "|")
  
  detection <- str_detect(df, pattern, negate = FALSE) %>%
    as.data.frame() %>% 
    mutate_all(as.character)
  
  suppressWarnings(str_detect(detection, "TRUE"))
}


number_of_clusters <- 20

#wow.. this takes 20 minutes
for(i in 1:nrow(new)) {
  for(j in 1:number_of_clusters){
  new[[paste0("cluster_",j)]][[i]] <- check.cluster.i(new$sentence[[i]], j)
}
}

new[new=="FALSE"]<-NA
```

```{r}
for(i in 1:number_of_clusters){
  ifelse(colnames(new)[10:ncol(new)][[i]]==paste("cluster", i, sep="_"), new[10:ncol(new)][[i]] <- str_replace(new[10:ncol(new)][[i]], "TRUE", paste(i)), "breaks")
}
```

```{r}

```




```{r}
library(tidyr)
vars <- c("sentence_id", paste0("cluster_", 1:20))
#work on this! make long for better EDA stuffs
long_new <- pivot_longer(new, cols = starts_with("cluster"), names_to="cluster")

median <- median(long_new$sentence_id)

# 0 --> 164: First section
# 164 --> 328: Second section
# 328 --> 656: Third section
# 656 --> 984: Fourth section
# 984 --> 1297: Fifth section
long_new <- long_new %>%
  filter(!is.na(value)) %>%
  select(sentences, id, doc_id, sentence_id, value) %>%
  mutate(quadrant = ifelse(sentence_id<=median/2, "Quadrant 1", ifelse(sentence_id <=median, "Quadrant 2", ifelse(sentence_id <= median*2, "Quadrant 3", ifelse(sentence_id <= median*3, "Quadrant 4", "Quadrant 5")))))
```

FOR EDA: line graphs of topics vs sentence number
How to do this????? Need to be able to make this a "timeline" with a count, but! each sentence has only one instance of a cluster if it is within that cluster. 

split up sentence ID into deciles or 5 groups etc.
restrict number of clusters to the "useful" ones, and perhaps group related clusters

```{r}
library(ggplot2)
long_new %>% 
  filter(id==1) %>%
  ggplot(aes(x=quadrant, y=value)) + geom_boxplot()
```





