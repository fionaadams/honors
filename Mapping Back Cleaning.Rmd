---
title: "Mapping Back Cleaning"
author: "Fiona Adams"
date: "1/16/2020"
output: html_document
---

Goal for this document: 
-take top words for each cluster, and map them to sentences
-find the synonyms using Julia Silge's methodology seen here: https://juliasilge.com/blog/tidy-word-vectors/
-find full sentences that use these words or the top # of synonyms to those words
```{r}
library(dplyr)
library(stringr)
```

Top words for cluster, mapped:
```{r}
words_in_clusters <- read.csv("words_in_clusters.csv")
words_in_clusters <- words_in_clusters %>% mutate_all(as.character)
new <- read.csv("sentence_level_clean.csv", header = TRUE)
new <- new %>%
    mutate(
        X = NULL,
        ID = as.character(ID),
        sentences = as.character(sentences)
    )
```

Goal:
-For each row in words_in_clusters, check if the top 20-30 words of each cluster (column) are in each row of new$sentences
-Then, make a new column named for the cluster (column) they are from, with a TRUE if that sentence (document) includes a word from the given cluster (column)

```{r}
library(dplyr)
library(stringr)
check.cluster.i <- function(df, i){
  listofwords <- words_in_clusters[,i+1]
  pattern <- paste(listofwords, collapse = "|")
  
  detection <- str_detect(df, pattern, negate = FALSE) %>%
    as.data.frame() %>% 
    mutate_all(as.character)
  
  suppressWarnings(str_detect(detection, "TRUE"))
}


number_of_clusters <- 20
for(i in 1:nrow(new)) {
  for(j in 1:number_of_clusters){
  new[[paste0("cluster_",j)]][[i]] <- check.cluster.i(new$sentences[[i]], j)
}
}
```

```{r}
write.csv(new, "testnew.csv")
```

```{r}
new <- read.csv("testnew.csv")
```

```{r}
new[new=="FALSE"]<-""

#now, automate
for(i in 1:number_of_clusters){
  ifelse(colnames(new)[5:ncol(new)][[i]]==paste("cluster", i, sep="_"), new[5:ncol(new)][[i]] <- str_replace(new[5:ncol(new)][[i]], "TRUE", paste("cluster", i, sep="_")), "breaks")
#str_replace(new[5:ncol(new)][[i]], "TRUE", paste("cluster", i, sep="_"))
}
```

```{r}
#make a column that shows all of the clusters in each sentence, if any
columns <- colnames(new)[5:ncol(new)]
new$clusters <- apply( new[ , columns ] , 1 , paste , collapse = " " )
```

Another idea for mapping:
-str_replace_all, replace words stigma -> topic1word1
-then, re-split the interview into sentences and see what words from the different topics are in there
-gives us the ability to see which topics are talked about in which order *within* a sentence
-would need to restrict to the *unique* words, or if the word is in multiple topics, ex. 2 3 and 4, say topic234word
-make graphic/table showing overlap in words between topics

