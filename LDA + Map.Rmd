---
title: "LDA + Map"
author: "Fiona Adams"
date: "2/9/2020"
output: html_document
---
```{r}
library(stringr)
```

```{r}
new <- read.csv("udpipe_clean_sentences.csv")
```

#Perform LDA
```{r echo=FALSE, warning=FALSE, results="hide", message=FALSE}
require(text2vec)

set.seed(397)

tokenlen = (length(new$sentence)/3) * 2

tokens = new$sentence[1:tokenlen] %>% 
  tolower %>%
  word_tokenizer

it = itoken(tokens, ids = new$id[1:tokenlen], progressbar = FALSE)
v = create_vocabulary(it) %>% 
  prune_vocabulary(term_count_min = 10, doc_proportion_max = 0.2)
vectorizer = vocab_vectorizer(v)
dtm = create_dtm(it, vectorizer, type = "dgTMatrix")

lda_model = LDA$new(n_topics = 20, doc_topic_prior = 0.1, topic_word_prior = 0.01)
doc_topic_distr = 
  lda_model$fit_transform(x = dtm, n_iter = tokenlen, 
                          convergence_tol = 0.001, n_check_convergence = 25, 
                          progressbar = FALSE)
```

Info on sharing this visualization: https://github.com/cpsievert/LDAvis
```{r message=FALSE}
library(LDAvis)
lda_model$plot()
```

#Extract cluster words, make only unique words
```{r}
words_in_clusters <- lda_model$get_top_words(n = 30, lambda = 0.3)
words_in_clusters <- as.data.frame(words_in_clusters) %>% 
  mutate_all(as.character)

write.csv(words_in_clusters, "words_in_clusters.csv")
```

#Map the clusters
```{r}
check.cluster.i <- function(df, i){
  listofwords <- words_in_clusters[,i]
  pattern <- paste(listofwords, collapse = "|")
  
  detection <- str_detect(df, pattern, negate = FALSE) %>%
    as.data.frame() %>% 
    mutate_all(as.character)
  
  suppressWarnings(str_detect(detection, "TRUE"))
}


number_of_clusters <- 20

#wow.. this takes 20 minutes
for(i in 1:nrow(new)) {
  for(j in 1:number_of_clusters){
  new[[paste0("cluster_",j)]][[i]] <- check.cluster.i(new$sentence[[i]], j)
}
}

new[new=="FALSE"]<- ""
```

```{r}
for(i in 1:number_of_clusters){
  ifelse(colnames(new)[10:ncol(new)][[i]]==paste("cluster", i, sep="_"), new[10:ncol(new)][[i]] <- str_replace(new[10:ncol(new)][[i]], "TRUE", paste(i)), "breaks")
}
```

```{r}
columns <- colnames(new)[11:ncol(new)]
new$clusters <- apply( new[ , columns ] , 1 , paste , collapse = "," )
```

```{r}
interviews_together <- new %>%
  group_by(id) %>%
  summarise(text=paste(sentence, clusters,collapse=" "))
```

```{r}
write.csv(new, "mapped_data.csv")
```





