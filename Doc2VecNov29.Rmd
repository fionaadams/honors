---
title: "Doc2Vec"
author: "Fiona Adams"
date: "11/29/2019"
output: html_document
---
```{r message=FALSE, warning=FALSE}
require(readtext)
library(dplyr)
source("Functions.R")

dat_word <- readtext("/Users/fionaadams/Documents/GitHub/honors/TranscriptTest/*.docx")
#words <- allphrases(dat_word)
```
```{r}
library(tidytext)
require(tm)
tidy_dat <- dat_word %>% 
  unnest_tokens(word,text) %>%
  mutate(word = tolower(word)) %>%
  anti_join(get_stopwords()) %>%
  group_by(word) %>%
  count() %>%
  filter(freq > 3) %>% #somewhat arbitrary? 
  mutate(p = freq / sum(freq))

require(widyr)
tidy_skipgrams <- dat_word %>%
    unnest_tokens(ngram, text, token = "ngrams", n = 8) %>%
    as.vector() %>%
    mutate(ngramID = 1:nrow(tidy_skipgrams)) %>%
#   mutate(ngramID = row_number()) %>% #row_number "should only be called in a data context"? Not working :(
#   unite(skipgramID, postID, ngramID) %>% #not sure where these other IDs come from?
    unnest_tokens(word, ngram)

skipgram_probs <- tidy_skipgrams %>%
    pairwise_count(word, skipgramID) %>%
    mutate(p = n / sum(n))
```


```{r}
library(tidyr)
sentiments = get_sentiments("bing") #choose lexicon from Bing Liu and collaborators
sentiment_dat <- tidy_dat %>% 
  inner_join(sentiments) %>%
  spread(sentiment, freq, fill=0) %>%
  mutate(sentiment=positive-negative) #gives neg numbers for neg sentiment, pos for pos
```







